<html>
<body>
<h4>Project 2: Faces!</h4>
<p>This project also has several baseline and extended options.  As
  before, you can work in teams of 1,2,3, the base option has a score of
  14/20, and the extensions have a score of (6 / #-of-people-in-the-group).
<ul>
<li>
<b>Option 1: Face Detection</b> 
The options considers the Viola Jones Face Detector.
The base option is to either start from scratch, or to complete the code
that we started from class.  The extensions are to explore different
facets of the Viola Jones training process, exploring different
features, different boosting approaches, or characterizing performce.

<ol>
<li>Base Option.
<ol>
<li>Implement Viola Jones.  You may use the following data sets.
Download both positive and negative training data here:
<ul>
<li> <a href="../matlabCode/faces.mat">faces.mat</a>, 
<li> <a href="../matlabCode/nonfaces.mat">nonfaces.mat</a>, or
<li> <a href="faceTrainingData.zip">zipped gifs</a>, 
</ul>
<li> You may use exactly the code linked from the class page to get
  started.  You need to write the function that takes in an image,
  computes the image pyramid, tests all the rectangles, and output the
  results.
<li> For the write up for the base option, you need to turn in:
<ol>
<li>Pseudo-code description of the algorithm, highlighting things
  like specifics of your image pyramid (how much smaller is each layer
  than the next).
<li>Re-train the classifier without the last 100 example faces and
  without the last 100 example non-faces, then use those 200 examples as
  "test-cases", and report classification accuracy (False Positive, True
  Positive, False Negative, and True Negative percentages).
<li>Report on total running time of both the training phase and the
per-image testing phase.
<li>Report on running time when using the integral images, versus not
  using the integral images.
</ol>
</ol>
<li>Extension 1.  Exploring completeness of the feature set.  The code
from class chose N features, and each feature was the best of M randomly
generated features.  The code online uses N=100, and M=20, whereas the
original Viola-Jones paper exhaustively explored all features and
included nearly 200 total features.  For this extension:
<ol>
<li> Characterize the performance (on the set aside test data), for
classifiers trained with different settings for N,M.  
<li> Based on your results, discuss which is more important.  Is it
  helpful to have more overall features (larger N?) or to try many more
  possible features when figuring out which feature to choose next (much
  larger M?).
</ol>
<li>Extension 2.  Exploring potential to speed up execution
<ol>
<li>Modify your base algorithm to use a cascade of filters (where you
  can mostly reject possible rectangles after just a few features are
  evaluated).  Section 4 of the 
<a href="http://research.microsoft.com/en-us/um/people/viola/pubs/detect/violajones_cvpr2001.pdf">original
  Viola Jones paper</a> discusses the original approach to building the
  cascade, you are encouraged to use this as a starting point to think
  about how to choose an ordered set of detectors, but are not required
  to exactly follow their model.
<li>Detail pseudo-code of your approach to building the cascade, running
  time to create the cascade, and improvements to the running time when
  using the cascade on sample images (versus not using the cascade).
</ol>
<li>Extension 3.  Explore different learning approaches.  My example
code from class uses a naive and partial implementation of boosted
learning.  In this extension, explore the variants of "GentleBoost" and
"AdaBoost" (or any other learning algorithm of your choice).  Present
  results in terms of training time and classification accuracy based on
  this approach.
<li>Extension 4.  Open ended exploration of features.  Viola Jones uses
  particular features defined on a 24 x 24 pixel face.  Explore any
  other set of features for face detection.
<ol>
<li>Give pseudocode for how you generate features
<li>Give running time comparison using your features vs. the rectangular
  features of Viola-Jones.
<li>Give classification accuracy of your features vs. rectangular
  features of Viola-Jones, for a complete classification system using
  the same number of total features.
</ol>
</ol>
<li><b>Option 2: Face Recognition</b>.  This project explores the use of
  PCA for recognition.  
<ol>
<li>Base option
<ol>
<li>Acquire and make sure that you can read in the images from:
<a
href="http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html">the
AT&T face database</a>
<li>Create the PCA decomposition of this set of images (you may shrink
the images so that this process all fits into memory), leaving out one
image per person (for later testing).
<li>For each test image, project it onto the PCA basis and compute
its coefficients.
<li>Find the training image with the most similar coefficients, and
record if this is an image of the same person.
<li>Report recognition accuracy results when the above process is done
with (a) just the mean image for each category, and (b,c,d,e) when
using 2 4 6 and 9 principle components.
</ol>
<li>Extension 1: Extend Base option to work on another data set
<ol>
<li>(This is probably *not* as easy as it seems).  There are a large
  number of data sets of labelled faces.  My favority is the
  <a href="http://www.openu.ac.il/home/hassner/data/lfwa/">"aligned
  labelled faces in the wild"</a> which is drawn from faces in AP news
  photos, and the faces are then warped and aligned into a common
  coordinate system.  The following is a zip file with about 40 of the
  most common faces <a href="lfwSmall.zip">link</a>.  These faces are 256
  x 256, but aligned so the eyes are in the same place and the face is
  the same size.
<li>Make reasonable choices for, and then report on (a) your choice of
  test and training data set -- which is not as clear because there are
  different numbers of faces for different people, (b) whether you get
  better performance when using the entire 256 x 256 image, or by using
  just the "central" face portion.  Discuss your results, which results
  are better?  Why?
<li>Discuss your results on this data set versus the data set in the
  base option.  Which results are better?  Why?
</ol>
<li>Extension 2: Explore pre-processing/larger set of features.  PCA
based recognition uses the PCA as a way to find basis images.  New
images are projected onto this basis in order to create a small set of
numbers which are used in recognition. This Extension allows you to
explore additional feature/bases.  You may try any novel feature set or
pre-processing you want, including but not limited to: (1) first
pre-process the image to compute an edge map, and run PCA on that, (2)
  use "Fisher Faces" instead of EigenFaces.
<ol>
<li>Report on: (a) what novel feature you used (at the pseudocode
  level), and what motivates that choice --- why might that be a good
  feature
<li>Give recognition accuracy for your features vs. PCA based
  recognition
<li>Explain why your results are better or worse.
</ol>
<li>Extension 3: You may do Extension 2 twice (with different novel
features).
</ol>
</ol>
</ul>
</body></html>



