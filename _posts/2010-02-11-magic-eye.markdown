---
layout: post
title: Project 1 - Magic Eye Puzzle
---

{{ page.title }}
============================================================

<p class="meta"/>11 Feb 2010 - St. Louis</p>

Problem Description
------------------------------------------------------------

For this project we were allowed to form groups to work on one of the two problems
together, however there was a catch.  For each added team member, the team would
have to solve an extra problem.  As such, it really only made sense for each
student to tackle the problem on their own and simply do the one extra problem
that they were on the hook for (which is the option I chose).

We were allowed to chose from two projects (and a number of extra sub-projects),
however this is the one that I decided to implement:

**Autostereogram Generator**
*(Not recommended if you can't see autostereograms)*

1.  *Base Project, [14 points]*

    Write a program that makes an autostereogram. This program must be automatic,
    and take in a depth map, and (perhaps a texture source, or you can generate
    the texture randomly). You turn in a web page, with your favorite (2 or 3)
    example outputs (and the depth map they came from). 

2.  *Extension, Worth [6 points]* 

    Moving autostereograms (good java choice). The idea here is to create a depth
    map that changes through time, and then show the autostereogram images through
    time (so that you see a moving depth map). This might entail creating a depth
    map that is a mathematical function that depends on time (or frame number t):

        d(x,y) = 4 + sin((x+t) / 150)

    Now, continually update the autostereograms as the depth map changes. This
    would be a nice java applet, or you could save the results as a movie
    (mpeg or avi). 

3.  *Extension, Worth [6 points]*

    Making *pretty* autostereograms. Random dot pictures are less compelling than
    many magic eye pictures. Create and detail how you created several images that
    are more compelling than random dot stereograms.


Solutions
------------------------------------------------------------

What follows is a pseudo-code description of the various algorithms I used to
generate the random dot autostereograms to complete the first part of the
assignment:

{% highlight python %}
    def create_random_dot(image):
      result = create_new_image(image.size)

      foreach h:0 to image.height:
        lookup = create_row_lookup(image[h])
        foreach w:0 to image.width:
          if point is not mapped in lookup map:
            result(w,h) = get_random_color()
          else if point is mapped in lookup:
            wl = get the mapped width point for this point
            result(w,h) = result(wl, h)
      return result
{% endhighlight %}

Next, in order to implement moving autostereograms, I took a simply shortcut.
Since *movement* was not well defined in the problem description, I decided
to simply rotate the image **(1)**:

{% highlight python %}
    images = []
    depthmap = Image.open("images/some-depthmap.jpg")
    for every 10 degrees in 360:
      map = depthmap.rotate(degrees)
      images.add(create_random_dot(map)
    save_images_as_animated_gif(images)
{% endhighlight %}

Finally, in order to use a texture to hide the depth information instead
of using random dots, I simply reused the existing lookup map creation
and then instead of using random colors to fill points, I just used
the specified texture pixels **(2)**.

{% highlight python %}
    def create_textured(image, texture):
      result = create_new_image(image.size)
      texture = validate_texture(texture)

      foreach h:0 to image.height:
        lookup = create_row_lookup(image[h])
        foreach w:0 to image.width:
          if point is not mapped in lookup map:
            x,y = get modulus values from texture
            result(w,h) = texture(x,y)
          else if point is mapped in lookup:
            wl = get the mapped width point for this point
            result(w,h) = result(wl, h)
      return result
{% endhighlight %}

The following utility functions were used in creating all the autostereograms:

{% highlight python %}
    def get_random_color():
      r = random_integer_generator
      return (r(255), r(255), r(255))

    def get_displacement(color):
      depth = using predetermined values, convert color value
              to a depth value for the given monitor.
      # compute the separation for the depth using similar triangles
      return (eye-separation * depth) / (depth + distance to viewer)

    def create_row_lookup(row):
      result = initialize with range from 0 to row width
      foreach w:0 to row.width:
        d = get_displacement(row[w])
        left, right = (w - d/2, w + d/2)
        if left and right are both in the image range:
          result[right] = left
      return result

    def validate_texture(texture):
      if texture.width is less than the max separation:
        resize the texture to be at least that and do so in a scaled
        manner (so height is increased in proportion to the width)
      return texture
{% endhighlight %}


General User Interface
------------------------------------------------------------

The entire project was presented as a python class with a collection of
helper functions.  As such, the user really only had to create a new
instance of the SIRD class with the depth-map to use and then call the
method of the type of stereogram to create.

The class simply loads the depth-map as well as any supplied texture
files, performs any pre-processing (making sure the texture file is
large enough to cover the max separation), and then uses the image
data as simple matrices to generate an autostereogram.

Discussion
------------------------------------------------------------

For the first implementation, I used the rough algorithm that Dr. Pless
had on the project description and quickly coded up a small script with
a few guessed numbers--it didn't work. After that I decided to rework 
the code into smaller methods and do some investigation on what kind
of separation was needed for my monitor and how that would be calculated
consistently.

After I had all the values pre-calculated, the random dot stereogram just
worked and as such the animated random dot stereogram worked as well
(since it was just creating N random dot stereograms). It did however
take a while to create and a good bit of disk space. The only problem I
faced after this portion was getting the textured stereogram working.

Since I had abstracted the separation point mapping, I was able to reuse
all the existing code and I simply had to worry with pulling the correct
pixel values from the texture.  At first this failed because my texture
was not wide enough to cover the separation needed to provide the correct
depth. After creating some pre-flight code to make sure the texture was
acceptable for the image, this portion worked as well.  The only thing that
remains is a bit of distortion in the resulting stereogram that can only
really be seen when using a texture that isn't abstract enough to hide it.

Demonstration of Successful Autostereogram Creations
------------------------------------------------------------

*What follows are a collection of autostereograms representing the various
required solutions for the problem sets. Open any image in a new window to
see it at full screen. It should be noted that the animated gif is 15 Mb*

**Random Dot Stereogram**

<img width="320" src="http://github.com/bashwork/school/raw/master/559/project1/images/boxes.jpg" />
<img width="320" src="http://github.com/bashwork/school/raw/master/559/project1/images/boxes-rd-sird.jpg" />

**Textured Stereogram**

<img width="320" src="http://github.com/bashwork/school/raw/master/559/project1/images/dino.jpg" />
<img width="320" src="http://github.com/bashwork/school/raw/master/559/project1/images/dino-textured-sird.jpg" />

**Animated Stereogram**

<img width="320" src="http://github.com/bashwork/school/raw/master/559/project1/images/human.gif" />
<img width="320" src="http://students.cec.wustl.edu/~gbc1/human-rd.gif" />


Code Used To Generate The Previous Images
------------------------------------------------------------

*The following is an example of creating a simple random dot stereogram*

{% highlight python %}
    from stereogram import SIRD
    
    sird  = SIRD("images/some-depth-map.jpg")
    image = sird.create_random_dot()
    image.show()
{% endhighlight %}

*In order to create a textured stereogram, the user simply needs to supply
the texture to use to hide the depth-map*

{% highlight python %}
    from stereogram import SIRD
    
    sird  = SIRD("images/some-depth-map.jpg")
    image = sird.create_texture("images/some-texture.jpg")
    image.show()
{% endhighlight %}

*In order to create an animated SIRD, the user first had to create
an image generator which they would then pass to the animated gif helper
library:*

{% highlight python %}
    from stereogram import SIRD
    import lib
    
    sird  = SIRD("images/some-depth-map.jpg")
    images = sird.create_animated_random_dot()
    lib.CreateAnimatedGif("output.gif", images)
{% endhighlight %}

Complete Source Code
------------------------------------------------------------

As already mentioned, this project was implemented in python and the full
code for all the solutions can be found in the following [repository][].
As for support libraries, the following were used throughout the project:

*  [Python Imaging Library(PIL)](http://www.pythonware.com/products/pil/)

   This was used for all the low level image management and manipulation
   like opening and saving image formats and getting and setting pixel
   values

*  [Numpy](http://numpy.scipy.org/)

   This was used to operate on multi-dimensional matrices in python

*  [VisVis](http://code.google.com/p/visvis/)

   This was used to save a list of PIL Images into an animated GIF


Footnotes
------------------------------------------------------------

1.  The only problems I had to worry about in this implementation is that PIL
    will keep the size of the image consistent during the rotation (so an image
    that is 1024x768 will stay 1024x768 when rotated 20 degrees) and pad the
    *excess* space with black (no depth information). However, this is not
    the case when the image is rotated 90 degrees.  This will cause the image
    to simply switch its width and height causing 2 frames of the video to
    be very distracting. Instead of skipping 90 degree rotations or resizing the
    image, I simply required animated depth-maps to be square.

2.  When I was reading William A. Steer's discussion on creating textured
    autostereograms, he mentioned a number of problems that he stumbled on
    such as random pixels sticking out and unwanted artifacts. Long story short,
    I took his word for it and implemented his error correcting ideas (copy
    adjacent pixel to prevent pixels on edges to stand out, etc). For more
    information [go to his page](http://www.techmind.org/stereo/stech.html).

  [repository]: http://github.com/bashwork/school/tree/master/559/project1/ "Master Repository"
